{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3947a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # ============================================================================\n",
    "# # MLP \n",
    "# # ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75f759cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Автопоиск файлов в проекте\n",
    "def find(f, r='..'):\n",
    "    for p, d, files in os.walk(r):\n",
    "        d[:] = [x for x in d if x not in ['.git', '__pycache__', '.ipynb_checkpoints']]\n",
    "        if f in files: return os.path.join(p, f)\n",
    "    raise FileNotFoundError(f\"'{f}' не найден!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da75cb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1] ЗАГРУЗКА ДАННЫХ...\n",
      " Train: 874,496 × 21\n",
      " Test: 107,260 × 21\n",
      "\n",
      " Загрузка embeddings...\n",
      " Train book embeddings: (874496, 768)\n",
      " Test book embeddings: (107260, 768)\n",
      " Baseline RMSE: 0.8104\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# [1] ЗАГРУЗКА ДАННЫХ \n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[1] ЗАГРУЗКА ДАННЫХ...\")\n",
    "\n",
    "# Feature engineering данные (17 числовых признаков)\n",
    "train_df = pd.read_csv(find('train_features_full.csv'))\n",
    "test_df = pd.read_csv(find('test_features_full.csv'))\n",
    "\n",
    "print(f\" Train: {len(train_df):,} × {train_df.shape[1]}\")\n",
    "print(f\" Test: {len(test_df):,} × {test_df.shape[1]}\")\n",
    "\n",
    "# Preprocessing embeddings \n",
    "print(\"\\n Загрузка embeddings...\")\n",
    "with open(find('train_embeddings.pkl'), 'rb') as f:\n",
    "    train_embeddings_pkl = pickle.load(f)\n",
    "\n",
    "with open(find('test_embeddings.pkl'), 'rb') as f:\n",
    "    test_embeddings_pkl = pickle.load(f)\n",
    "\n",
    "# Извлекаем book embeddings (768-dim)\n",
    "train_book_emb = train_embeddings_pkl['book_emb']\n",
    "test_book_emb = test_embeddings_pkl['book_emb']\n",
    "\n",
    "print(f\" Train book embeddings: {train_book_emb.shape}\")\n",
    "print(f\" Test book embeddings: {test_book_emb.shape}\")\n",
    "\n",
    "# Baseline\n",
    "with open(find('baseline_artifacts.pkl'), 'rb') as f:\n",
    "    baseline_artifacts = pickle.load(f)\n",
    "\n",
    "baseline_rmse = baseline_artifacts['best_baseline_rmse']\n",
    "print(f\" Baseline RMSE: {baseline_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a8e741c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2] СОЗДАНИЕ ПРИЗНАКОВ...\n",
      " Базовых признаков: 18\n",
      " Embedding признаков: 768\n",
      " ВСЕГО: 786\n",
      "\n",
      " X_train: (874496, 786)\n",
      " X_test: (107260, 786)\n",
      "\n",
      "[3] ОБУЧЕНИЕ MLP...\n",
      " NN train: (743321, 786)\n",
      " NN val: (131175, 786)\n",
      " Нормализация завершена\n",
      "\n",
      " Архитектура: Input(786) → Dense(128) → Dense(64) → Output(1)\n",
      "Iteration 1, loss = 0.33763621\n",
      "Validation score: 0.374129\n",
      "Iteration 2, loss = 0.29842484\n",
      "Validation score: 0.381988\n",
      "Iteration 3, loss = 0.29125489\n",
      "Validation score: 0.401923\n",
      "Iteration 4, loss = 0.28682646\n",
      "Validation score: 0.405178\n",
      "Iteration 5, loss = 0.28406278\n",
      "Validation score: 0.405419\n",
      "Iteration 6, loss = 0.28163529\n",
      "Validation score: 0.407705\n",
      "Iteration 7, loss = 0.27911023\n",
      "Validation score: 0.411542\n",
      "Iteration 8, loss = 0.27705440\n",
      "Validation score: 0.414508\n",
      "Iteration 9, loss = 0.27529693\n",
      "Validation score: 0.419745\n",
      "Iteration 10, loss = 0.27354051\n",
      "Validation score: 0.414633\n",
      "Iteration 11, loss = 0.27200140\n",
      "Validation score: 0.417496\n",
      "Iteration 12, loss = 0.27102742\n",
      "Validation score: 0.424777\n",
      "Iteration 13, loss = 0.26962749\n",
      "Validation score: 0.424444\n",
      "Iteration 14, loss = 0.26873451\n",
      "Validation score: 0.423674\n",
      "Iteration 15, loss = 0.26776437\n",
      "Validation score: 0.423508\n",
      "Iteration 16, loss = 0.26687205\n",
      "Validation score: 0.427890\n",
      "Iteration 17, loss = 0.26593312\n",
      "Validation score: 0.428557\n",
      "Iteration 18, loss = 0.26536503\n",
      "Validation score: 0.429466\n",
      "Iteration 19, loss = 0.26436906\n",
      "Validation score: 0.427950\n",
      "Iteration 20, loss = 0.26374932\n",
      "Validation score: 0.426525\n",
      "Iteration 21, loss = 0.26328494\n",
      "Validation score: 0.422711\n",
      "Iteration 22, loss = 0.26240662\n",
      "Validation score: 0.427045\n",
      "Iteration 23, loss = 0.26193166\n",
      "Validation score: 0.426681\n",
      "Iteration 24, loss = 0.26131109\n",
      "Validation score: 0.425968\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
      "\n",
      " Обучение завершено за 12.2 минут\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# [2] СОЗДАНИЕ ПРИЗНАКОВ \n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[2] СОЗДАНИЕ ПРИЗНАКОВ...\")\n",
    "\n",
    "# 17 числовых признаков\n",
    "numeric_features = [\n",
    "    # Interaction (6)\n",
    "    'tag_overlap_count', 'tag_overlap_ratio', 'tag_jaccard',\n",
    "    'history_similarity', 'embedding_cosine_sim', 'embedding_euclidean_dist',\n",
    "    # User (4)\n",
    "    'avg_user_rating', 'ratings_count', 'tag_vocab_size', 'activity_score',\n",
    "    # Book (3)\n",
    "    'book_avg_rating', 'book_ratings_count', 'book_popularity',\n",
    "    # Preprocessing (4)\n",
    "    'language_code_encoded', 'year_normalized', 'publication_era', 'average_rating'\n",
    "]\n",
    "\n",
    "# Энкодим segment\n",
    "segment_mapping = {'new': 0, 'inactive': 1, 'active': 2, 'very_active': 3}\n",
    "train_df['segment_encoded'] = train_df['segment'].map(segment_mapping).fillna(1)\n",
    "test_df['segment_encoded'] = test_df['segment'].map(segment_mapping).fillna(1)\n",
    "\n",
    "# Базовый набор: 17 + 1 = 18\n",
    "base_features = numeric_features + ['segment_encoded']\n",
    "\n",
    "# Создаем DataFrame с embeddings\n",
    "emb_columns = [f'book_emb_{i}' for i in range(768)]\n",
    "train_emb_df = pd.DataFrame(train_book_emb, columns=emb_columns, index=train_df.index)\n",
    "test_emb_df = pd.DataFrame(test_book_emb, columns=emb_columns, index=test_df.index)\n",
    "\n",
    "# Полный набор: 18 + 768 = 786\n",
    "all_features = base_features + emb_columns\n",
    "\n",
    "print(f\" Базовых признаков: {len(base_features)}\")\n",
    "print(f\" Embedding признаков: {len(emb_columns)}\")\n",
    "print(f\" ВСЕГО: {len(all_features)}\")\n",
    "\n",
    "# Объединяем базовые + embeddings\n",
    "X_train_full = pd.concat([\n",
    "    train_df[base_features].reset_index(drop=True),\n",
    "    train_emb_df.reset_index(drop=True)\n",
    "], axis=1).values\n",
    "\n",
    "X_test_full = pd.concat([\n",
    "    test_df[base_features].reset_index(drop=True),\n",
    "    test_emb_df.reset_index(drop=True)\n",
    "], axis=1).values\n",
    "\n",
    "y_train_full = train_df['rating'].values\n",
    "y_test = test_df['rating'].values\n",
    "\n",
    "print(f\"\\n X_train: {X_train_full.shape}\")\n",
    "print(f\" X_test: {X_test_full.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# [3] ОБУЧЕНИЕ MLP\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[3] ОБУЧЕНИЕ MLP...\")\n",
    "\n",
    "# Split train/val\n",
    "X_train_nn, X_val_nn, y_train_nn, y_val_nn = train_test_split(\n",
    "    X_train_full, y_train_full,\n",
    "    test_size=0.15,\n",
    "    random_state=42,\n",
    "    stratify=y_train_full\n",
    ")\n",
    "\n",
    "print(f\" NN train: {X_train_nn.shape}\")\n",
    "print(f\" NN val: {X_val_nn.shape}\")\n",
    "\n",
    "# Нормализация\n",
    "scaler_nn = StandardScaler()\n",
    "X_train_nn_scaled = scaler_nn.fit_transform(X_train_nn)\n",
    "X_val_nn_scaled = scaler_nn.transform(X_val_nn)\n",
    "X_test_nn_scaled = scaler_nn.transform(X_test_full)\n",
    "\n",
    "print(\" Нормализация завершена\")\n",
    "\n",
    "# Обучение\n",
    "print(\"\\n Архитектура: Input(786) → Dense(128) → Dense(64) → Output(1)\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "mlp = MLPRegressor(\n",
    "    hidden_layer_sizes=(128, 64),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    learning_rate_init=1e-3,\n",
    "    batch_size=256,\n",
    "    max_iter=30,\n",
    "    random_state=42,\n",
    "    verbose=True,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=5\n",
    ")\n",
    "\n",
    "mlp.fit(X_train_nn_scaled, y_train_nn)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"\\n Обучение завершено за {training_time/60:.1f} минут\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8002fdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "БАЗОВЫЕ МЕТРИКИ\n",
      "================================================================================\n",
      "\n",
      "Валидация (15% train):\n",
      "  RMSE: 0.7414\n",
      "  MAE:  0.5676\n",
      "\n",
      " Test:\n",
      "  RMSE:        0.8288\n",
      "  MAE:         0.6331\n",
      "  Improvement: -2.27% vs baseline\n",
      "\n",
      " RMSE по rating buckets:\n",
      "  RMSE (rating ≤3): 1.1754\n",
      "  RMSE (rating ≥4): 0.5745\n",
      "\n",
      "================================================================================\n",
      "RANKING METRICS: Precision@K, Recall@K, nDCG@K\n",
      "================================================================================\n",
      "\n",
      " Загрузка test_dataset.csv...\n",
      " Загружено: 107,260 записей\n",
      "\n",
      " Загрузка предсказаний других моделей...\n",
      "\n",
      " Расчёт baseline predictions...\n",
      " Всего пользователей: 35,659\n",
      "\n",
      " Расчёт ranking metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing users: 100%|██████████| 35659/35659 [00:26<00:00, 1370.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RANKING METRICS: РЕЗУЛЬТАТЫ\n",
      "================================================================================\n",
      "\n",
      " K=1:\n",
      "Model                          Precision@1  Recall@1     nDCG@1      \n",
      "----------------------------------------------------------------------\n",
      "\n",
      " K=2:\n",
      "Model                          Precision@2  Recall@2     nDCG@2      \n",
      "----------------------------------------------------------------------\n",
      "\n",
      " K=3:\n",
      "Model                          Precision@3  Recall@3     nDCG@3      \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "СРАВНЕНИЕ: MLP vs Optimized Ensemble (лучшая по RMSE)\n",
      "================================================================================\n",
      "\n",
      " K=1:\n",
      "  Precision: 0.8802 (Ensemble) vs 0.8828 (MLP)  (+0.29%)\n",
      "  Recall:    0.4730 (Ensemble) vs 0.4755 (MLP)  (+0.52%)\n",
      "  nDCG:      0.9517 (Ensemble) vs 0.9502 (MLP)  (-0.16%)\n",
      "\n",
      " K=2:\n",
      "  Precision: 0.7802 (Ensemble) vs 0.7794 (MLP)  (-0.10%)\n",
      "  Recall:    0.7602 (Ensemble) vs 0.7597 (MLP)  (-0.07%)\n",
      "  nDCG:      0.9661 (Ensemble) vs 0.9653 (MLP)  (-0.09%)\n",
      "\n",
      " K=3:\n",
      "  Precision: 0.6610 (Ensemble) vs 0.6610 (MLP)  (-0.01%)\n",
      "  Recall:    0.9123 (Ensemble) vs 0.9123 (MLP)  (-0.01%)\n",
      "  nDCG:      0.9843 (Ensemble) vs 0.9839 (MLP)  (-0.04%)\n",
      "\n",
      "================================================================================\n",
      "СРАВНЕНИЕ: MLP vs Baseline\n",
      "================================================================================\n",
      "\n",
      " K=1:\n",
      "  Precision: 0.7213 → 0.8828  (+22.40%)\n",
      "  Recall:    0.3479 → 0.4755  (+36.69%)\n",
      "  nDCG:      0.7985 → 0.9502  (+19.00%)\n",
      "\n",
      " K=2:\n",
      "  Precision: 0.6931 → 0.7794  (+12.46%)\n",
      "  Recall:    0.6502 → 0.7597  (+16.83%)\n",
      "  nDCG:      0.8571 → 0.9653  (+12.62%)\n",
      "\n",
      " K=3:\n",
      "  Precision: 0.6608 → 0.6610  (+0.03%)\n",
      "  Recall:    0.9121 → 0.9123  (+0.02%)\n",
      "  nDCG:      0.9332 → 0.9839  (+5.44%)\n",
      "\n",
      "================================================================================\n",
      " СВОДНАЯ ТАБЛИЦА: RMSE + RANKING METRICS\n",
      "================================================================================\n",
      "\n",
      "               Model     RMSE  Precision@1  Recall@1   nDCG@1\n",
      "  Optimized Ensemble 0.758542     0.880227  0.472992 0.951688\n",
      "            CatBoost 0.773136     0.886817  0.478558 0.958676\n",
      "Baseline (User+Book) 0.810425     0.721277  0.347853 0.798516\n",
      "  MLP (786 features) 0.828797     0.882807  0.475473 0.950212\n",
      "\n",
      "================================================================================\n",
      " ОЦЕНКА ЗАВЕРШЕНА\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# [4] ОЦЕНКА\n",
    "# ============================================================================\n",
    "\n",
    "# === Базовые метрики (RMSE, MAE) ===\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"БАЗОВЫЕ МЕТРИКИ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Валидация\n",
    "mlp_pred_val = mlp.predict(X_val_nn_scaled)\n",
    "mlp_rmse_val = np.sqrt(mean_squared_error(y_val_nn, np.clip(mlp_pred_val, 1, 5)))\n",
    "mlp_mae_val = mean_absolute_error(y_val_nn, np.clip(mlp_pred_val, 1, 5))\n",
    "\n",
    "print(f\"\\nВалидация (15% train):\")\n",
    "print(f\"  RMSE: {mlp_rmse_val:.4f}\")\n",
    "print(f\"  MAE:  {mlp_mae_val:.4f}\")\n",
    "\n",
    "# Test\n",
    "mlp_pred_test = mlp.predict(X_test_nn_scaled)\n",
    "mlp_rmse_test = np.sqrt(mean_squared_error(y_test, np.clip(mlp_pred_test, 1, 5)))\n",
    "mlp_mae_test = mean_absolute_error(y_test, np.clip(mlp_pred_test, 1, 5))\n",
    "mlp_improvement = (baseline_rmse - mlp_rmse_test) / baseline_rmse * 100\n",
    "\n",
    "print(f\"\\n Test:\")\n",
    "print(f\"  RMSE:        {mlp_rmse_test:.4f}\")\n",
    "print(f\"  MAE:         {mlp_mae_test:.4f}\")\n",
    "print(f\"  Improvement: {mlp_improvement:+.2f}% vs baseline\")\n",
    "\n",
    "# По buckets\n",
    "low_mask = y_test <= 3\n",
    "high_mask = y_test >= 4\n",
    "\n",
    "mlp_rmse_low = np.sqrt(mean_squared_error(y_test[low_mask], np.clip(mlp_pred_test[low_mask], 1, 5)))\n",
    "mlp_rmse_high = np.sqrt(mean_squared_error(y_test[high_mask], np.clip(mlp_pred_test[high_mask], 1, 5)))\n",
    "\n",
    "print(f\"\\n RMSE по rating buckets:\")\n",
    "print(f\"  RMSE (rating ≤3): {mlp_rmse_low:.4f}\")\n",
    "print(f\"  RMSE (rating ≥4): {mlp_rmse_high:.4f}\")\n",
    "\n",
    "\n",
    "# === RANKING METRICS ===\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RANKING METRICS: Precision@K, Recall@K, nDCG@K\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# Функции для расчёта\n",
    "def precision_at_k(y_true, y_pred, k=3, threshold=4.0):\n",
    "    \"\"\"Precision@K: доля релевантных книг в топ-K\"\"\"\n",
    "    k_actual = min(k, len(y_pred))\n",
    "    if k_actual == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    top_k_idx = np.argsort(y_pred)[::-1][:k_actual]\n",
    "    relevant_in_top_k = sum(y_true[i] >= threshold for i in top_k_idx)\n",
    "    return relevant_in_top_k / k_actual\n",
    "\n",
    "\n",
    "def recall_at_k(y_true, y_pred, k=3, threshold=4.0):\n",
    "    \"\"\"Recall@K: какую долю релевантных книг нашли\"\"\"\n",
    "    total_relevant = sum(y_true >= threshold)\n",
    "    \n",
    "    if total_relevant == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    k_actual = min(k, len(y_pred))\n",
    "    top_k_idx = np.argsort(y_pred)[::-1][:k_actual]\n",
    "    relevant_in_top_k = sum(y_true[i] >= threshold for i in top_k_idx)\n",
    "    return relevant_in_top_k / total_relevant\n",
    "\n",
    "\n",
    "def ndcg_at_k(y_true, y_pred, k=3):\n",
    "    \"\"\"nDCG@K: качество ранжирования\"\"\"\n",
    "    k_actual = min(k, len(y_pred))\n",
    "    if k_actual == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    top_k_idx = np.argsort(y_pred)[::-1][:k_actual]\n",
    "    \n",
    "    dcg = sum((2**y_true[i] - 1) / np.log2(pos + 2) \n",
    "              for pos, i in enumerate(top_k_idx))\n",
    "    \n",
    "    ideal_idx = np.argsort(y_true)[::-1][:k_actual]\n",
    "    idcg = sum((2**y_true[i] - 1) / np.log2(pos + 2) \n",
    "               for pos, i in enumerate(ideal_idx))\n",
    "    \n",
    "    if idcg == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return dcg / idcg\n",
    "\n",
    "\n",
    "# Загружаем test_dataset для user_id\n",
    "print(\"\\n Загрузка test_dataset.csv...\")\n",
    "test_dataset = pd.read_csv(find('test_dataset.csv'))\n",
    "print(f\" Загружено: {len(test_dataset):,} записей\")\n",
    "\n",
    "# Группируем по пользователям\n",
    "test_with_pred = test_dataset[['user_id']].copy()\n",
    "test_with_pred['y_true'] = y_test\n",
    "test_with_pred['y_pred_mlp'] = np.clip(mlp_pred_test, 1, 5)\n",
    "\n",
    "# Загружаем предсказания других моделей для сравнения\n",
    "print(\"\\n Загрузка предсказаний других моделей...\")\n",
    "predictions_dict = np.load(find('ml_predictions_full.npy'), allow_pickle=True).item()\n",
    "\n",
    "test_with_pred['y_pred_catboost'] = predictions_dict['catboost']\n",
    "test_with_pred['y_pred_ensemble'] = predictions_dict['catboost'] * 0.15 + \\\n",
    "                                    predictions_dict['lightgbm'] * 0.35 + \\\n",
    "                                    predictions_dict['knn_features'] * 0.50\n",
    "\n",
    "# Baseline predictions\n",
    "print(\"\\n Расчёт baseline predictions...\")\n",
    "with open(find('baseline_artifacts.pkl'), 'rb') as f:\n",
    "    baseline_artifacts = pickle.load(f)\n",
    "\n",
    "global_mean = baseline_artifacts['global_mean']\n",
    "user_bias_dict = baseline_artifacts['user_bias_dict']\n",
    "book_bias_dict = baseline_artifacts['book_bias_dict']\n",
    "\n",
    "def predict_baseline(user_id, book_id):\n",
    "    pred = global_mean\n",
    "    pred += user_bias_dict.get(user_id, 0)\n",
    "    pred += book_bias_dict.get(book_id, 0)\n",
    "    return np.clip(pred, 1, 5)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "baseline_pred_test = np.array([\n",
    "    predict_baseline(row['user_id'], row['book_id'])\n",
    "    for _, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Baseline\", disable=True)\n",
    "])\n",
    "\n",
    "test_with_pred['y_pred_baseline'] = baseline_pred_test\n",
    "\n",
    "# Группируем по user_id\n",
    "user_groups = test_with_pred.groupby('user_id')\n",
    "\n",
    "print(f\" Всего пользователей: {len(user_groups):,}\")\n",
    "\n",
    "\n",
    "# Расчёт метрик для всех моделей\n",
    "k_values = [1, 2, 3]\n",
    "\n",
    "models_to_compare = {\n",
    "    'Baseline (User+Book)': 'y_pred_baseline',\n",
    "    'CatBoost': 'y_pred_catboost',\n",
    "    'Optimized Ensemble': 'y_pred_ensemble',\n",
    "    'MLP (786 features)': 'y_pred_mlp'\n",
    "}\n",
    "\n",
    "results = {\n",
    "    model_name: {k: {\"precision\": [], \"recall\": [], \"ndcg\": []} for k in k_values}\n",
    "    for model_name in models_to_compare.keys()\n",
    "}\n",
    "\n",
    "print(\"\\n Расчёт ranking metrics...\")\n",
    "\n",
    "for user_id, group in tqdm(user_groups, desc=\"Processing users\", total=len(user_groups)):\n",
    "    y_true_user = group['y_true'].values\n",
    "    \n",
    "    if len(y_true_user) < 1:\n",
    "        continue\n",
    "    \n",
    "    for model_name, col_name in models_to_compare.items():\n",
    "        y_pred_user = group[col_name].values\n",
    "        \n",
    "        for k in k_values:\n",
    "            results[model_name][k][\"precision\"].append(\n",
    "                precision_at_k(y_true_user, y_pred_user, k)\n",
    "            )\n",
    "            results[model_name][k][\"recall\"].append(\n",
    "                recall_at_k(y_true_user, y_pred_user, k)\n",
    "            )\n",
    "            results[model_name][k][\"ndcg\"].append(\n",
    "                ndcg_at_k(y_true_user, y_pred_user, k)\n",
    "            )\n",
    "\n",
    "\n",
    "# === ВЫВОД РЕЗУЛЬТАТОВ ===\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RANKING METRICS: РЕЗУЛЬТАТЫ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for k in k_values:\n",
    "    print(f\"\\n K={k}:\")\n",
    "    print(f\"{'Model':<30} {'Precision@{}'.format(k):<12} {'Recall@{}'.format(k):<12} {'nDCG@{}'.format(k):<12}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for model_name in models_to_compare.keys():\n",
    "        p = np.mean(results[model_name][k]['precision'])\n",
    "        r = np.mean(results[model_name][k]['recall'])\n",
    "        n = np.mean(results[model_name][k]['ndcg'])\n",
    "        \n",
    "        \n",
    "\n",
    "# === СРАВНЕНИЕ MLP vs ENSEMBLE (лучшая) ===\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"СРАВНЕНИЕ: MLP vs Optimized Ensemble (лучшая по RMSE)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "mlp_key = 'MLP (786 features)'\n",
    "best_key = 'Optimized Ensemble'\n",
    "\n",
    "for k in k_values:\n",
    "    mlp_p = np.mean(results[mlp_key][k]['precision'])\n",
    "    best_p = np.mean(results[best_key][k]['precision'])\n",
    "    \n",
    "    mlp_r = np.mean(results[mlp_key][k]['recall'])\n",
    "    best_r = np.mean(results[best_key][k]['recall'])\n",
    "    \n",
    "    mlp_n = np.mean(results[mlp_key][k]['ndcg'])\n",
    "    best_n = np.mean(results[best_key][k]['ndcg'])\n",
    "    \n",
    "    imp_p = ((mlp_p - best_p) / best_p * 100) if best_p > 0 else 0\n",
    "    imp_r = ((mlp_r - best_r) / best_r * 100) if best_r > 0 else 0\n",
    "    imp_n = ((mlp_n - best_n) / best_n * 100) if best_n > 0 else 0\n",
    "    \n",
    "    print(f\"\\n K={k}:\")\n",
    "    print(f\"  Precision: {best_p:.4f} (Ensemble) vs {mlp_p:.4f} (MLP)  ({imp_p:+.2f}%)\")\n",
    "    print(f\"  Recall:    {best_r:.4f} (Ensemble) vs {mlp_r:.4f} (MLP)  ({imp_r:+.2f}%)\")\n",
    "    print(f\"  nDCG:      {best_n:.4f} (Ensemble) vs {mlp_n:.4f} (MLP)  ({imp_n:+.2f}%)\")\n",
    "\n",
    "\n",
    "# === СРАВНЕНИЕ MLP vs BASELINE ===\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"СРАВНЕНИЕ: MLP vs Baseline\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "baseline_key = 'Baseline (User+Book)'\n",
    "\n",
    "for k in k_values:\n",
    "    mlp_p = np.mean(results[mlp_key][k]['precision'])\n",
    "    baseline_p = np.mean(results[baseline_key][k]['precision'])\n",
    "    \n",
    "    mlp_r = np.mean(results[mlp_key][k]['recall'])\n",
    "    baseline_r = np.mean(results[baseline_key][k]['recall'])\n",
    "    \n",
    "    mlp_n = np.mean(results[mlp_key][k]['ndcg'])\n",
    "    baseline_n = np.mean(results[baseline_key][k]['ndcg'])\n",
    "    \n",
    "    imp_p = ((mlp_p - baseline_p) / baseline_p * 100) if baseline_p > 0 else 0\n",
    "    imp_r = ((mlp_r - baseline_r) / baseline_r * 100) if baseline_r > 0 else 0\n",
    "    imp_n = ((mlp_n - baseline_n) / baseline_n * 100) if baseline_n > 0 else 0\n",
    "    \n",
    "    print(f\"\\n K={k}:\")\n",
    "    print(f\"  Precision: {baseline_p:.4f} → {mlp_p:.4f}  ({imp_p:+.2f}%)\")\n",
    "    print(f\"  Recall:    {baseline_r:.4f} → {mlp_r:.4f}  ({imp_r:+.2f}%)\")\n",
    "    print(f\"  nDCG:      {baseline_n:.4f} → {mlp_n:.4f}  ({imp_n:+.2f}%)\")\n",
    "\n",
    "\n",
    "# === ТАБЛИЦА ДЛЯ ОТЧЁТА ===\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" СВОДНАЯ ТАБЛИЦА: RMSE + RANKING METRICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary_data = []\n",
    "for model_name in models_to_compare.keys():\n",
    "    # RMSE\n",
    "    if model_name == 'Baseline (User+Book)':\n",
    "        rmse = baseline_rmse\n",
    "    elif model_name == 'MLP (786 features)':\n",
    "        rmse = mlp_rmse_test\n",
    "    elif model_name == 'CatBoost':\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, np.clip(predictions_dict['catboost'], 1, 5)))\n",
    "    elif model_name == 'Optimized Ensemble':\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, np.clip(test_with_pred['y_pred_ensemble'].values, 1, 5)))\n",
    "    \n",
    "    # Ranking metrics (K=1)\n",
    "    p1 = np.mean(results[model_name][1]['precision'])\n",
    "    r1 = np.mean(results[model_name][1]['recall'])\n",
    "    n1 = np.mean(results[model_name][1]['ndcg'])\n",
    "    \n",
    "    summary_data.append({\n",
    "        'Model': model_name,\n",
    "        'RMSE': rmse,\n",
    "        'Precision@1': p1,\n",
    "        'Recall@1': r1,\n",
    "        'nDCG@1': n1\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df = summary_df.sort_values('RMSE')\n",
    "\n",
    "print(\"\\n\" + summary_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" ОЦЕНКА ЗАВЕРШЕНА\")\n",
    "print(\"=\"*80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ff877cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5] СРАВНЕНИЕ...\n",
      "\n",
      "======================================================================\n",
      "Model                          RMSE       Improvement    \n",
      "======================================================================\n",
      "[BASELINE]                     0.8104     -              \n",
      "----------------------------------------------------------------------\n",
      "CatBoost (786 features)        0.7731     +4.60%\n",
      "LightGBM (786 features)        0.7869     +2.90%\n",
      "KNN (786 features)             0.7819     +3.51%\n",
      "MLP (786 features)             0.8288     -2.27%\n",
      "======================================================================\n",
      "\n",
      " MLP: 4 место из 4 моделей\n",
      "\n",
      "[6] STACKING С MLP...\n",
      "\n",
      " Коэффициенты Ridge:\n",
      "   CatBoost: -0.0883\n",
      "   LightGBM: +0.3859\n",
      "   KNN: +0.3126\n",
      "   MLP: +0.3590\n",
      "\n",
      " Stacking:\n",
      "   RMSE: 0.7178\n",
      "   MAE: 0.5724\n",
      "   Улучшение: +11.44%\n",
      "\n",
      "[7] СОХРАНЕНИЕ...\n",
      " Сохранено: mlp_model_786.pkl\n",
      " Сохранено: mlp_predictions_786.npy\n",
      " Сохранено: stacking_with_mlp_786.pkl\n",
      "\n",
      "================================================================================\n",
      "ГОТОВО!\n",
      "================================================================================\n",
      "\n",
      " MLP (786 признаков): 0.8288 (-2.27%)\n",
      " Stacking: 0.7178 (+11.44%)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# [5] СРАВНЕНИЕ С ДРУГИМИ МОДЕЛЯМИ\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[5] СРАВНЕНИЕ...\")\n",
    "\n",
    "# Загружаем готовые предсказания\n",
    "predictions_dict = np.load(find('ml_predictions_full.npy'), allow_pickle=True).item()\n",
    "\n",
    "catboost_pred = predictions_dict['catboost']\n",
    "lgb_pred = predictions_dict['lightgbm']\n",
    "knn_pred = predictions_dict['knn_features']\n",
    "\n",
    "comparison = {\n",
    "    'Model': [\n",
    "        '[BASELINE]',\n",
    "        'CatBoost (786 features)',\n",
    "        'LightGBM (786 features)',\n",
    "        'KNN (786 features)',\n",
    "        'MLP (786 features)'\n",
    "    ],\n",
    "    'RMSE': [\n",
    "        baseline_rmse,\n",
    "        np.sqrt(mean_squared_error(y_test, np.clip(catboost_pred, 1, 5))),\n",
    "        np.sqrt(mean_squared_error(y_test, np.clip(lgb_pred, 1, 5))),\n",
    "        np.sqrt(mean_squared_error(y_test, np.clip(knn_pred, 1, 5))),\n",
    "        mlp_rmse_test\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_comp = pd.DataFrame(comparison)\n",
    "df_comp['Improvement'] = (baseline_rmse - df_comp['RMSE']) / baseline_rmse * 100\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"{'Model':<30} {'RMSE':<10} {'Improvement':<15}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for _, row in df_comp.iterrows():\n",
    "    if 'BASELINE' in row['Model']:\n",
    "        print(f\"{row['Model']:<30} {row['RMSE']:<10.4f} {'-':<15}\")\n",
    "        print(\"-\"*70)\n",
    "    else:\n",
    "        print(f\"{row['Model']:<30} {row['RMSE']:<10.4f} {row['Improvement']:+.2f}%\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Позиция MLP\n",
    "better_models = sum(df_comp.iloc[1:4]['RMSE'] < mlp_rmse_test)\n",
    "mlp_rank = better_models + 1\n",
    "print(f\"\\n MLP: {mlp_rank} место из 4 моделей\")\n",
    "\n",
    "# ============================================================================\n",
    "# [6] STACKING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[6] STACKING С MLP...\")\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "X_meta = np.column_stack([\n",
    "    catboost_pred,\n",
    "    lgb_pred,\n",
    "    knn_pred,\n",
    "    mlp_pred_test\n",
    "])\n",
    "\n",
    "X_meta_train, X_meta_val, y_meta_train, y_meta_val = train_test_split(\n",
    "    X_meta, y_test,\n",
    "    test_size=0.5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "meta_model = Ridge(alpha=1.0)\n",
    "meta_model.fit(X_meta_train, y_meta_train)\n",
    "\n",
    "stacking_pred = meta_model.predict(X_meta_val)\n",
    "\n",
    "stacking_rmse = np.sqrt(mean_squared_error(y_meta_val, np.clip(stacking_pred, 1, 5)))\n",
    "stacking_mae = mean_absolute_error(y_meta_val, np.clip(stacking_pred, 1, 5))\n",
    "stacking_improvement = (baseline_rmse - stacking_rmse) / baseline_rmse * 100\n",
    "\n",
    "print(f\"\\n Коэффициенты Ridge:\")\n",
    "print(f\"   CatBoost: {meta_model.coef_[0]:+.4f}\")\n",
    "print(f\"   LightGBM: {meta_model.coef_[1]:+.4f}\")\n",
    "print(f\"   KNN: {meta_model.coef_[2]:+.4f}\")\n",
    "print(f\"   MLP: {meta_model.coef_[3]:+.4f}\")\n",
    "\n",
    "print(f\"\\n Stacking:\")\n",
    "print(f\"   RMSE: {stacking_rmse:.4f}\")\n",
    "print(f\"   MAE: {stacking_mae:.4f}\")\n",
    "print(f\"   Улучшение: {stacking_improvement:+.2f}%\")\n",
    "\n",
    "# ============================================================================\n",
    "# [7] СОХРАНЕНИЕ\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[7] СОХРАНЕНИЕ...\")\n",
    "\n",
    "with open   (find('mlp_model_786.pkl'), 'wb') as f:\n",
    "    pickle.dump({'model': mlp, 'scaler': scaler_nn}, f)\n",
    "\n",
    "np.save(find('mlp_predictions_786.npy'), {\n",
    "    'test': mlp_pred_test,\n",
    "    'validation': mlp_pred_val,\n",
    "    'y_test': y_test,\n",
    "    'rmse': mlp_rmse_test\n",
    "})\n",
    "\n",
    "with open('stacking_with_mlp_786.pkl', 'wb') as f:\n",
    "    pickle.dump({'model': meta_model, 'rmse': stacking_rmse}, f)\n",
    "\n",
    "print(\" Сохранено: mlp_model_786.pkl\")\n",
    "print(\" Сохранено: mlp_predictions_786.npy\")\n",
    "print(\" Сохранено: stacking_with_mlp_786.pkl\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ГОТОВО!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n MLP (786 признаков): {mlp_rmse_test:.4f} ({mlp_improvement:+.2f}%)\")\n",
    "print(f\" Stacking: {stacking_rmse:.4f} ({stacking_improvement:+.2f}%)\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b6dffd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5] СРАВНЕНИЕ...\n",
      "\n",
      "================================================================================\n",
      "СРАВНЕНИЕ: RMSE\n",
      "================================================================================\n",
      "\n",
      "Model                          RMSE       Improvement    \n",
      "------------------------------------------------------------\n",
      "[BASELINE]                     0.8104     -              \n",
      "  CatBoost (786 features)      0.7731     +4.60%\n",
      "  LightGBM (786 features)      0.7869     +2.90%\n",
      "  KNN (786 features)           0.7819     +3.51%\n",
      "* MLP (786 features)           0.8288     -2.27%\n",
      "\n",
      " MLP: 4 место из 4 ML-моделей по RMSE\n",
      "\n",
      "================================================================================\n",
      "СРАВНЕНИЕ: RANKING METRICS\n",
      "================================================================================\n",
      "\n",
      " Загрузка test_dataset.csv...\n",
      " Расчёт baseline predictions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Пользователей: 35,659\n",
      "\n",
      " Расчёт ranking metrics для всех моделей...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 35659/35659 [00:15<00:00, 2236.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RANKING METRICS: Все модели\n",
      "================================================================================\n",
      "\n",
      " K=1:\n",
      "Model           Precision@1   Recall@1      nDCG@1       \n",
      "------------------------------------------------------------\n",
      "\n",
      " K=2:\n",
      "Model           Precision@2   Recall@2      nDCG@2       \n",
      "------------------------------------------------------------\n",
      "\n",
      " K=3:\n",
      "Model           Precision@3   Recall@3      nDCG@3       \n",
      "------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "СРАВНЕНИЕ: MLP vs CatBoost (лучшая по RMSE)\n",
      "================================================================================\n",
      "\n",
      " K=1:\n",
      "  Precision: 0.8868 (CatBoost) vs 0.8828 (MLP)  [-0.45%]\n",
      "  Recall:    0.4786 (CatBoost) vs 0.4755 (MLP)  [-0.64%]\n",
      "  nDCG:      0.9587 (CatBoost) vs 0.9502 (MLP)  [-0.88%]\n",
      "\n",
      " K=2:\n",
      "  Precision: 0.7831 (CatBoost) vs 0.7794 (MLP)  [-0.47%]\n",
      "  Recall:    0.7635 (CatBoost) vs 0.7597 (MLP)  [-0.51%]\n",
      "  nDCG:      0.9704 (CatBoost) vs 0.9653 (MLP)  [-0.53%]\n",
      "\n",
      " K=3:\n",
      "  Precision: 0.6610 (CatBoost) vs 0.6610 (MLP)  [-0.01%]\n",
      "  Recall:    0.9124 (CatBoost) vs 0.9123 (MLP)  [-0.01%]\n",
      "  nDCG:      0.9865 (CatBoost) vs 0.9839 (MLP)  [-0.26%]\n",
      "\n",
      "================================================================================\n",
      "[6] STACKING С MLP...\n",
      "================================================================================\n",
      "\n",
      " Коэффициенты Ridge:\n",
      "  CatBoost: -0.0883\n",
      "  LightGBM: +0.3859\n",
      "  KNN:      +0.3126\n",
      "  MLP:      +0.3590\n",
      "\n",
      " Stacking результаты:\n",
      "  RMSE:        0.7178\n",
      "  MAE:         0.5724\n",
      "  Improvement: +11.44% vs baseline\n",
      "\n",
      "================================================================================\n",
      "RANKING METRICS: Stacking с MLP\n",
      "================================================================================\n",
      " Пользователей в stacking validation: 17,843\n",
      "\n",
      " Расчёт ranking metrics для stacking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 17843/17843 [00:05<00:00, 3539.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RANKING METRICS: Сравнение Stacking\n",
      "================================================================================\n",
      "\n",
      " K=1:\n",
      "Model                                    Precision@1   Recall@1      nDCG@1       \n",
      "-------------------------------------------------------------------------------------\n",
      "\n",
      " K=2:\n",
      "Model                                    Precision@2   Recall@2      nDCG@2       \n",
      "-------------------------------------------------------------------------------------\n",
      "\n",
      " K=3:\n",
      "Model                                    Precision@3   Recall@3      nDCG@3       \n",
      "-------------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "УЛУЧШЕНИЕ: Stacking vs CatBoost (лучшая одиночная)\n",
      "================================================================================\n",
      "\n",
      " K=1:\n",
      "  Precision: 0.6613 → 0.8781  [+32.79%]\n",
      "  Recall:    0.3202 → 0.4760  [+48.67%]\n",
      "  nDCG:      0.6816 → 0.8923  [+30.93%]\n",
      "\n",
      " K=2:\n",
      "  Precision: 0.6596 → 0.7843  [+18.90%]\n",
      "  Recall:    0.6386 → 0.7942  [+24.38%]\n",
      "  nDCG:      0.7725 → 0.9279  [+20.11%]\n",
      "\n",
      " K=3:\n",
      "  Precision: 0.6603 → 0.6608  [+0.08%]\n",
      "  Recall:    0.9598 → 0.9605  [+0.07%]\n",
      "  nDCG:      0.8922 → 0.9650  [+8.16%]\n",
      "\n",
      "================================================================================\n",
      "[7] СОХРАНЕНИЕ...\n",
      "================================================================================\n",
      " Сохранено: mlp_model_786.pkl\n",
      " Сохранено: mlp_predictions_786.npy\n",
      " Сохранено: stacking_with_mlp_786.pkl\n",
      " Сохранено: mlp_summary_results.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# [5] СРАВНЕНИЕ С ДРУГИМИ МОДЕЛЯМИ + RANKING METRICS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[5] СРАВНЕНИЕ...\")\n",
    "\n",
    "# Загружаем готовые предсказания\n",
    "predictions_dict = np.load(find('ml_predictions_full.npy'), allow_pickle=True).item()\n",
    "\n",
    "catboost_pred = predictions_dict['catboost']\n",
    "lgb_pred = predictions_dict['lightgbm']\n",
    "knn_pred = predictions_dict['knn_features']\n",
    "\n",
    "# === БАЗОВЫЕ МЕТРИКИ (RMSE) ===\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"СРАВНЕНИЕ: RMSE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison = {\n",
    "    'Model': [\n",
    "        '[BASELINE]',\n",
    "        'CatBoost (786 features)',\n",
    "        'LightGBM (786 features)',\n",
    "        'KNN (786 features)',\n",
    "        'MLP (786 features)'\n",
    "    ],\n",
    "    'RMSE': [\n",
    "        baseline_rmse,\n",
    "        np.sqrt(mean_squared_error(y_test, np.clip(catboost_pred, 1, 5))),\n",
    "        np.sqrt(mean_squared_error(y_test, np.clip(lgb_pred, 1, 5))),\n",
    "        np.sqrt(mean_squared_error(y_test, np.clip(knn_pred, 1, 5))),\n",
    "        mlp_rmse_test\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_comp = pd.DataFrame(comparison)\n",
    "df_comp['Improvement'] = (baseline_rmse - df_comp['RMSE']) / baseline_rmse * 100\n",
    "\n",
    "print(f\"\\n{'Model':<30} {'RMSE':<10} {'Improvement':<15}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for _, row in df_comp.iterrows():\n",
    "    if 'BASELINE' in row['Model']:\n",
    "        print(f\"{row['Model']:<30} {row['RMSE']:<10.4f} {'-':<15}\")\n",
    "    else:\n",
    "        marker = \"MLP\" in row['Model'] and \"*\" or \" \"\n",
    "        print(f\"{marker} {row['Model']:<28} {row['RMSE']:<10.4f} {row['Improvement']:+.2f}%\")\n",
    "\n",
    "# Позиция MLP\n",
    "better_models = sum(df_comp.iloc[1:4]['RMSE'] < mlp_rmse_test)\n",
    "mlp_rank = better_models + 1\n",
    "print(f\"\\n MLP: {mlp_rank} место из 4 ML-моделей по RMSE\")\n",
    "\n",
    "\n",
    "# === RANKING METRICS ===\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"СРАВНЕНИЕ: RANKING METRICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# Функции для ranking metrics\n",
    "def precision_at_k(y_true, y_pred, k=3, threshold=4.0):\n",
    "    \"\"\"Precision@K\"\"\"\n",
    "    k_actual = min(k, len(y_pred))\n",
    "    if k_actual == 0:\n",
    "        return 0.0\n",
    "    top_k_idx = np.argsort(y_pred)[::-1][:k_actual]\n",
    "    relevant_in_top_k = sum(y_true[i] >= threshold for i in top_k_idx)\n",
    "    return relevant_in_top_k / k_actual\n",
    "\n",
    "def recall_at_k(y_true, y_pred, k=3, threshold=4.0):\n",
    "    \"\"\"Recall@K\"\"\"\n",
    "    total_relevant = sum(y_true >= threshold)\n",
    "    if total_relevant == 0:\n",
    "        return 0.0\n",
    "    k_actual = min(k, len(y_pred))\n",
    "    top_k_idx = np.argsort(y_pred)[::-1][:k_actual]\n",
    "    relevant_in_top_k = sum(y_true[i] >= threshold for i in top_k_idx)\n",
    "    return relevant_in_top_k / total_relevant\n",
    "\n",
    "def ndcg_at_k(y_true, y_pred, k=3):\n",
    "    \"\"\"nDCG@K\"\"\"\n",
    "    k_actual = min(k, len(y_pred))\n",
    "    if k_actual == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    top_k_idx = np.argsort(y_pred)[::-1][:k_actual]\n",
    "    dcg = sum((2**y_true[i] - 1) / np.log2(pos + 2) \n",
    "              for pos, i in enumerate(top_k_idx))\n",
    "    \n",
    "    ideal_idx = np.argsort(y_true)[::-1][:k_actual]\n",
    "    idcg = sum((2**y_true[i] - 1) / np.log2(pos + 2) \n",
    "               for pos, i in enumerate(ideal_idx))\n",
    "    \n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "\n",
    "# Загружаем test_dataset для user_id\n",
    "print(\"\\n Загрузка test_dataset.csv...\")\n",
    "test_dataset = pd.read_csv(find('test_dataset.csv'))\n",
    "\n",
    "# Baseline predictions\n",
    "print(\" Расчёт baseline predictions...\")\n",
    "with open(find('baseline_artifacts.pkl'), 'rb') as f:\n",
    "    baseline_artifacts = pickle.load(f)\n",
    "\n",
    "global_mean = baseline_artifacts['global_mean']\n",
    "user_bias_dict = baseline_artifacts['user_bias_dict']\n",
    "book_bias_dict = baseline_artifacts['book_bias_dict']\n",
    "\n",
    "def predict_baseline(user_id, book_id):\n",
    "    pred = global_mean + user_bias_dict.get(user_id, 0) + book_bias_dict.get(book_id, 0)\n",
    "    return np.clip(pred, 1, 5)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "baseline_pred_test = np.array([\n",
    "    predict_baseline(row['user_id'], row['book_id'])\n",
    "    for _, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Baseline\", leave=False)\n",
    "])\n",
    "\n",
    "# Создаём датафрейм с предсказаниями всех моделей\n",
    "test_with_pred = test_dataset[['user_id']].copy()\n",
    "test_with_pred['y_true'] = y_test\n",
    "test_with_pred['baseline'] = baseline_pred_test\n",
    "test_with_pred['catboost'] = catboost_pred\n",
    "test_with_pred['lightgbm'] = lgb_pred\n",
    "test_with_pred['knn'] = knn_pred\n",
    "test_with_pred['mlp'] = np.clip(mlp_pred_test, 1, 5)\n",
    "\n",
    "# Группируем по user_id\n",
    "user_groups = test_with_pred.groupby('user_id')\n",
    "\n",
    "print(f\" Пользователей: {len(user_groups):,}\")\n",
    "\n",
    "\n",
    "# Расчёт ranking metrics\n",
    "k_values = [1, 2, 3]\n",
    "\n",
    "models = {\n",
    "    'Baseline': 'baseline',\n",
    "    'CatBoost': 'catboost',\n",
    "    'LightGBM': 'lightgbm',\n",
    "    'KNN': 'knn',\n",
    "    'MLP': 'mlp'\n",
    "}\n",
    "\n",
    "results = {\n",
    "    model: {k: {\"precision\": [], \"recall\": [], \"ndcg\": []} for k in k_values}\n",
    "    for model in models.keys()\n",
    "}\n",
    "\n",
    "print(\"\\n Расчёт ranking metrics для всех моделей...\")\n",
    "\n",
    "for user_id, group in tqdm(user_groups, desc=\"Processing\", total=len(user_groups)):\n",
    "    y_true_user = group['y_true'].values\n",
    "    \n",
    "    if len(y_true_user) < 1:\n",
    "        continue\n",
    "    \n",
    "    for model_name, col_name in models.items():\n",
    "        y_pred_user = group[col_name].values\n",
    "        \n",
    "        for k in k_values:\n",
    "            results[model_name][k][\"precision\"].append(precision_at_k(y_true_user, y_pred_user, k))\n",
    "            results[model_name][k][\"recall\"].append(recall_at_k(y_true_user, y_pred_user, k))\n",
    "            results[model_name][k][\"ndcg\"].append(ndcg_at_k(y_true_user, y_pred_user, k))\n",
    "\n",
    "\n",
    "# Вывод результатов\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RANKING METRICS: Все модели\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for k in k_values:\n",
    "    print(f\"\\n K={k}:\")\n",
    "    print(f\"{'Model':<15} {'Precision@{}'.format(k):<13} {'Recall@{}'.format(k):<13} {'nDCG@{}'.format(k):<13}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for model_name in models.keys():\n",
    "        p = np.mean(results[model_name][k]['precision'])\n",
    "        r = np.mean(results[model_name][k]['recall'])\n",
    "        n = np.mean(results[model_name][k]['ndcg'])\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "# Сравнение MLP с лучшей моделью\n",
    "best_model_name = min(\n",
    "    [m for m in models.keys() if m != 'Baseline'],\n",
    "    key=lambda m: df_comp[df_comp['Model'].str.contains(m.split()[0])]['RMSE'].values[0]\n",
    ")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"СРАВНЕНИЕ: MLP vs {best_model_name} (лучшая по RMSE)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for k in k_values:\n",
    "    mlp_p = np.mean(results['MLP'][k]['precision'])\n",
    "    best_p = np.mean(results[best_model_name][k]['precision'])\n",
    "    \n",
    "    mlp_r = np.mean(results['MLP'][k]['recall'])\n",
    "    best_r = np.mean(results[best_model_name][k]['recall'])\n",
    "    \n",
    "    mlp_n = np.mean(results['MLP'][k]['ndcg'])\n",
    "    best_n = np.mean(results[best_model_name][k]['ndcg'])\n",
    "    \n",
    "    imp_p = ((mlp_p - best_p) / best_p * 100) if best_p > 0 else 0\n",
    "    imp_r = ((mlp_r - best_r) / best_r * 100) if best_r > 0 else 0\n",
    "    imp_n = ((mlp_n - best_n) / best_n * 100) if best_n > 0 else 0\n",
    "    \n",
    "    print(f\"\\n K={k}:\")\n",
    "    print(f\"  Precision: {best_p:.4f} ({best_model_name}) vs {mlp_p:.4f} (MLP)  [{imp_p:+.2f}%]\")\n",
    "    print(f\"  Recall:    {best_r:.4f} ({best_model_name}) vs {mlp_r:.4f} (MLP)  [{imp_r:+.2f}%]\")\n",
    "    print(f\"  nDCG:      {best_n:.4f} ({best_model_name}) vs {mlp_n:.4f} (MLP)  [{imp_n:+.2f}%]\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# [6] STACKING + RANKING METRICS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"[6] STACKING С MLP...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "X_meta = np.column_stack([\n",
    "    catboost_pred,\n",
    "    lgb_pred,\n",
    "    knn_pred,\n",
    "    mlp_pred_test\n",
    "])\n",
    "\n",
    "X_meta_train, X_meta_val, y_meta_train, y_meta_val = train_test_split(\n",
    "    X_meta, y_test,\n",
    "    test_size=0.5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "meta_model = Ridge(alpha=1.0)\n",
    "meta_model.fit(X_meta_train, y_meta_train)\n",
    "\n",
    "stacking_pred = meta_model.predict(X_meta_val)\n",
    "\n",
    "stacking_rmse = np.sqrt(mean_squared_error(y_meta_val, np.clip(stacking_pred, 1, 5)))\n",
    "stacking_mae = mean_absolute_error(y_meta_val, np.clip(stacking_pred, 1, 5))\n",
    "stacking_improvement = (baseline_rmse - stacking_rmse) / baseline_rmse * 100\n",
    "\n",
    "print(f\"\\n Коэффициенты Ridge:\")\n",
    "print(f\"  CatBoost: {meta_model.coef_[0]:+.4f}\")\n",
    "print(f\"  LightGBM: {meta_model.coef_[1]:+.4f}\")\n",
    "print(f\"  KNN:      {meta_model.coef_[2]:+.4f}\")\n",
    "print(f\"  MLP:      {meta_model.coef_[3]:+.4f}\")\n",
    "\n",
    "print(f\"\\n Stacking результаты:\")\n",
    "print(f\"  RMSE:        {stacking_rmse:.4f}\")\n",
    "print(f\"  MAE:         {stacking_mae:.4f}\")\n",
    "print(f\"  Improvement: {stacking_improvement:+.2f}% vs baseline\")\n",
    "\n",
    "\n",
    "# === RANKING METRICS ДЛЯ STACKING ===\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RANKING METRICS: Stacking с MLP\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Индексы для meta_val\n",
    "meta_val_indices = X_meta_train.shape[0] + np.arange(X_meta_val.shape[0])\n",
    "\n",
    "# Создаём датафрейм для stacking\n",
    "test_with_stacking = test_dataset.iloc[meta_val_indices].copy()\n",
    "test_with_stacking['y_true'] = y_meta_val\n",
    "test_with_stacking['stacking'] = np.clip(stacking_pred, 1, 5)\n",
    "\n",
    "# Добавляем предсказания других моделей для сравнения\n",
    "test_with_stacking['catboost'] = catboost_pred[meta_val_indices]\n",
    "test_with_stacking['mlp'] = np.clip(mlp_pred_test[meta_val_indices], 1, 5)\n",
    "\n",
    "# Группируем\n",
    "user_groups_stacking = test_with_stacking.groupby('user_id')\n",
    "\n",
    "print(f\" Пользователей в stacking validation: {len(user_groups_stacking):,}\")\n",
    "\n",
    "# Расчёт метрик для stacking\n",
    "models_stacking = {\n",
    "    'CatBoost (лучшая одиночная)': 'catboost',\n",
    "    'MLP': 'mlp',\n",
    "    'Stacking (CatBoost+LightGBM+KNN+MLP)': 'stacking'\n",
    "}\n",
    "\n",
    "results_stacking = {\n",
    "    model: {k: {\"precision\": [], \"recall\": [], \"ndcg\": []} for k in k_values}\n",
    "    for model in models_stacking.keys()\n",
    "}\n",
    "\n",
    "print(\"\\n Расчёт ranking metrics для stacking...\")\n",
    "\n",
    "for user_id, group in tqdm(user_groups_stacking, desc=\"Processing\", total=len(user_groups_stacking)):\n",
    "    y_true_user = group['y_true'].values\n",
    "    \n",
    "    if len(y_true_user) < 1:\n",
    "        continue\n",
    "    \n",
    "    for model_name, col_name in models_stacking.items():\n",
    "        y_pred_user = group[col_name].values\n",
    "        \n",
    "        for k in k_values:\n",
    "            results_stacking[model_name][k][\"precision\"].append(precision_at_k(y_true_user, y_pred_user, k))\n",
    "            results_stacking[model_name][k][\"recall\"].append(recall_at_k(y_true_user, y_pred_user, k))\n",
    "            results_stacking[model_name][k][\"ndcg\"].append(ndcg_at_k(y_true_user, y_pred_user, k))\n",
    "\n",
    "\n",
    "# Вывод результатов\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RANKING METRICS: Сравнение Stacking\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for k in k_values:\n",
    "    print(f\"\\n K={k}:\")\n",
    "    print(f\"{'Model':<40} {'Precision@{}'.format(k):<13} {'Recall@{}'.format(k):<13} {'nDCG@{}'.format(k):<13}\")\n",
    "    print(\"-\" * 85)\n",
    "    \n",
    "    for model_name in models_stacking.keys():\n",
    "        p = np.mean(results_stacking[model_name][k]['precision'])\n",
    "        r = np.mean(results_stacking[model_name][k]['recall'])\n",
    "        n = np.mean(results_stacking[model_name][k]['ndcg'])\n",
    "        \n",
    "       \n",
    "\n",
    "\n",
    "# Улучшение Stacking vs CatBoost\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"УЛУЧШЕНИЕ: Stacking vs CatBoost (лучшая одиночная)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for k in k_values:\n",
    "    catboost_p = np.mean(results_stacking['CatBoost (лучшая одиночная)'][k]['precision'])\n",
    "    stacking_p = np.mean(results_stacking['Stacking (CatBoost+LightGBM+KNN+MLP)'][k]['precision'])\n",
    "    \n",
    "    catboost_r = np.mean(results_stacking['CatBoost (лучшая одиночная)'][k]['recall'])\n",
    "    stacking_r = np.mean(results_stacking['Stacking (CatBoost+LightGBM+KNN+MLP)'][k]['recall'])\n",
    "    \n",
    "    catboost_n = np.mean(results_stacking['CatBoost (лучшая одиночная)'][k]['ndcg'])\n",
    "    stacking_n = np.mean(results_stacking['Stacking (CatBoost+LightGBM+KNN+MLP)'][k]['ndcg'])\n",
    "    \n",
    "    imp_p = ((stacking_p - catboost_p) / catboost_p * 100) if catboost_p > 0 else 0\n",
    "    imp_r = ((stacking_r - catboost_r) / catboost_r * 100) if catboost_r > 0 else 0\n",
    "    imp_n = ((stacking_n - catboost_n) / catboost_n * 100) if catboost_n > 0 else 0\n",
    "    \n",
    "    print(f\"\\n K={k}:\")\n",
    "    print(f\"  Precision: {catboost_p:.4f} → {stacking_p:.4f}  [{imp_p:+.2f}%]\")\n",
    "    print(f\"  Recall:    {catboost_r:.4f} → {stacking_r:.4f}  [{imp_r:+.2f}%]\")\n",
    "    print(f\"  nDCG:      {catboost_n:.4f} → {stacking_n:.4f}  [{imp_n:+.2f}%]\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# [7] СОХРАНЕНИЕ\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"[7] СОХРАНЕНИЕ...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Модель MLP\n",
    "with open(find('mlp_model_786.pkl'), 'wb') as f:\n",
    "    pickle.dump({'model': mlp, 'scaler': scaler_nn}, f)\n",
    "\n",
    "print(\" Сохранено: mlp_model_786.pkl\")\n",
    "\n",
    "# Предсказания MLP\n",
    "np.save(find('mlp_predictions_786.npy'), {\n",
    "    'test': mlp_pred_test,\n",
    "    'validation': mlp_pred_val,\n",
    "    'y_test': y_test,\n",
    "    'rmse': mlp_rmse_test,\n",
    "    'ranking_results': {\n",
    "        k: {\n",
    "            'precision': float(np.mean(results['MLP'][k]['precision'])),\n",
    "            'recall': float(np.mean(results['MLP'][k]['recall'])),\n",
    "            'ndcg': float(np.mean(results['MLP'][k]['ndcg']))\n",
    "        }\n",
    "        for k in k_values\n",
    "    }\n",
    "})\n",
    "\n",
    "print(\" Сохранено: mlp_predictions_786.npy\")\n",
    "\n",
    "# Stacking model\n",
    "with open(find('stacking_with_mlp_786.pkl'), 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'model': meta_model,\n",
    "        'rmse': stacking_rmse,\n",
    "        'mae': stacking_mae,\n",
    "        'improvement': stacking_improvement,\n",
    "        'coefficients': {\n",
    "            'catboost': float(meta_model.coef_[0]),\n",
    "            'lightgbm': float(meta_model.coef_[1]),\n",
    "            'knn': float(meta_model.coef_[2]),\n",
    "            'mlp': float(meta_model.coef_[3])\n",
    "        },\n",
    "        'ranking_results': {\n",
    "            k: {\n",
    "                'precision': float(np.mean(results_stacking['Stacking (CatBoost+LightGBM+KNN+MLP)'][k]['precision'])),\n",
    "                'recall': float(np.mean(results_stacking['Stacking (CatBoost+LightGBM+KNN+MLP)'][k]['recall'])),\n",
    "                'ndcg': float(np.mean(results_stacking['Stacking (CatBoost+LightGBM+KNN+MLP)'][k]['ndcg']))\n",
    "            }\n",
    "            for k in k_values\n",
    "        }\n",
    "    }, f)\n",
    "\n",
    "print(\" Сохранено: stacking_with_mlp_786.pkl\")\n",
    "\n",
    "# Сводная таблица для отчёта\n",
    "summary_df = pd.DataFrame({\n",
    "    'Model': ['MLP', 'Stacking (с MLP)'],\n",
    "    'RMSE': [mlp_rmse_test, stacking_rmse],\n",
    "    'MAE': [mlp_mae_test, stacking_mae],\n",
    "    'Precision@1': [\n",
    "        np.mean(results['MLP'][1]['precision']),\n",
    "        np.mean(results_stacking['Stacking (CatBoost+LightGBM+KNN+MLP)'][1]['precision'])\n",
    "    ],\n",
    "    'Recall@1': [\n",
    "        np.mean(results['MLP'][1]['recall']),\n",
    "        np.mean(results_stacking['Stacking (CatBoost+LightGBM+KNN+MLP)'][1]['recall'])\n",
    "    ],\n",
    "    'nDCG@1': [\n",
    "        np.mean(results['MLP'][1]['ndcg']),\n",
    "        np.mean(results_stacking['Stacking (CatBoost+LightGBM+KNN+MLP)'][1]['ndcg'])\n",
    "    ]\n",
    "})\n",
    "\n",
    "summary_df.to_csv('mlp_summary_results.csv', index=False)\n",
    "print(\" Сохранено: mlp_summary_results.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e14150",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl_env_cuda)",
   "language": "python",
   "name": "dl_env_cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
